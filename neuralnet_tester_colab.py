# -*- coding: utf-8 -*-
"""NeuralNet_Tester_Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ErgGkizOYxa2sGaNvckm0tb2Bksu7fZm
"""

import tensorflow as tf
from tensorflow import keras
from keras import layers, models, callbacks
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import cv2
import ast
import json
import sklearn
from sklearn.utils import class_weight

from keras import mixed_precision
mixed_precision.set_global_policy('mixed_float16')

###Can be removed if not using colab
from google.colab import drive
drive.mount('/content/drive')

"""Extracts annotations from a .tar.gz file into a separate path"""
def extract_tar_gz(tar_path, extract_path):
  import tarfile
  import os

  # Ensure the extraction directory exists
  os.makedirs(extract_path, exist_ok=True)

  with tarfile.open(tar_path, "r:gz") as tar:
      # Extract all contents to the specified path
      tar.extractall(path=extract_path)

  print(f"Extracted contents to: {extract_path}")

def load_images(csv_data, image_dir):
  loaded_images = []
  for i in range(len(csv_data)):
    img_path = csv_data['file_name'][i] #creates a path using the folder(drive) and the filename as found in the csv
    img_path = image_dir + "/" + img_path
    if os.path.exists(img_path): # Check if the file exists
      img = cv2.imread(img_path)
      img = cv2.resize(img, (96, 96))
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      if img is not None:
        loaded_images.append(img)
      else:
        print(f"Image not found: {img_path}")
        loaded_images.append(None)

  return loaded_images

def load_images2(csv_data,  image_dir):
  loaded_images = []
  for i in range(len(csv_data)):
    img_path = csv_data['Filename'][i] #creates a path using the folder(drive) and the filename as found in the csv
    img_path = image_dir + "/" + img_path
    if os.path.exists(img_path): # Check if the file exists
      img = cv2.imread(img_path)
      img = cv2.resize(img, (96, 96))
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      if img is not None:
        loaded_images.append(img)
      else:
        print(f"Image not found: {img_path}")
        loaded_images.append(None)
    else:
      print("file " + img_path + " doesnt exist")
  return loaded_images

def WFLW_tester(tar_path, extract_path, image_dir, csv_path):
  extract_tar_gz(tar_path, extract_path)
  csv_data = pd.read_csv(csv_path)
  print("There are", len(csv_data), "WFLW testing annotations.")
  loaded_images = load_images(csv_data, image_dir)
  print("Loaded all", len(loaded_images), "testing images.")
  return csv_data, loaded_images

from sklearn.utils.class_weight import compute_class_weight

def get_class_weights(labels):
    labels = np.array(labels)
    classes = np.unique(labels)
    weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels)
    return dict(zip(classes, weights))
#print(np.unique(csv_data['make_up']).tolist())
#class_weights = get_class_weights(csv_data['make_up'])
#print(class_weights)

def loaded_model(model_path, attribute):
  path = model_path + attribute + '.keras'
  if attribute == 'make_up' or 'illumination':
    model = keras.models.load_model(path)
  elif attribute == 'blur' or 'expression' or 'occlusion' or 'pose':
    model = keras.models.model_from_json(open(path).read())
  else:
    print(attribute, "Model not found")
    return None
  return model

def test_all(model_path, csv_data, loaded_images):
  x = np.array(loaded_images)

  csv_data_headers = ['blur', 'occlusion', 'make_up', 'expression', 'illumination', 'pose']
  to_plot = []
  for header in csv_data_headers:
    y = csv_data[header].to_numpy()
    y = y.astype(int)
    model = loaded_model(model_path, header)
    eval_result = model.evaluate(x, y)
    print(header, "accuracy:", eval_result[1])
    to_plot.append(eval_result[1])

  plt.bar(csv_data_headers, to_plot, color='blue')
  plt.xlabel("Attribute")
  plt.ylabel("Accuracy")
  plt.title("Model Accuracy by Attribute")
  plt.show()

def my_imgs_tester(illumination_csv_data, image_dir2, model_path):
  print("There are", len(illumination_csv_data), "testing annotations.")
  loaded_images = load_images2(illumination_csv_data,image_dir2)
  print("Loaded all", len(loaded_images), "testing images.")
  illumination = keras.models.load_model(model_path +'illumination.keras')
  x = np.array(loaded_images)
  y = illumination_csv_data['Indication'].to_numpy()
  y = y.astype(int)
  eval_result = illumination.evaluate(x, y)
  print("illumination accuracy on my images:", eval_result[1])

def main():

  ###CONSTANTS### --- Manipulate according to your filepaths
  tar_path = "/content/drive/MyDrive/WFLW_images.tar.gz" #must be a zipped tar.gz file
  extract_path = "/content/WFLW_images" #path to unzip the images
  image_dir = "/content/WFLW_images/WFLW_images" #path to directory containing images- within extract_path
  csv_path = "/content/drive/MyDrive/Colab Notebooks/saving_tester.csv" #path to saving_tester.csv (output from annotations_parser.py)
  model_path = "/content/drive/MyDrive/Colab Notebooks/models/" #path to trained models

  illumination_csv_data = pd.read_csv("/content/drive/MyDrive/image-lightings.csv") #csv file of own images (output from image-lighting-calc.py)
  image_dir2 = '/content/drive/MyDrive/all-images'#directory containing own images that image-lighting-calc.py computed illumination values of

  ###MAIN###
  csv_data, loaded_images = WFLW_tester(tar_path, extract_path, image_dir, csv_path)
  test_all(model_path, csv_data, loaded_images)
  import time
  time.sleep(10)
  #my_imgs_tester(illumination_csv_data, image_dir2, model_path)


if __name__ == "__main__":
    main()